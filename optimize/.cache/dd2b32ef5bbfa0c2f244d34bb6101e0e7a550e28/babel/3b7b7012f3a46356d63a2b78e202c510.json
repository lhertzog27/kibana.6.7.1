{"remainingRequest":"/home/anthony/git_workspaces/kibana/node_modules/thread-loader/dist/cjs.js??ref--9-1!/home/anthony/git_workspaces/kibana/node_modules/babel-loader/lib/index.js??ref--9-2!/home/anthony/git_workspaces/kibana/x-pack/plugins/ml/public/explorer/explorer_charts/explorer_charts_container_service.js","dependencies":[{"path":"/home/anthony/git_workspaces/kibana/x-pack/plugins/ml/public/explorer/explorer_charts/explorer_charts_container_service.js","mtime":1567631712041},{"path":"/home/anthony/git_workspaces/kibana/node_modules/cache-loader/dist/cjs.js","mtime":1567666236302},{"path":"/home/anthony/git_workspaces/kibana/node_modules/thread-loader/dist/cjs.js","mtime":1567666239443},{"path":"/home/anthony/git_workspaces/kibana/node_modules/babel-loader/lib/index.js","mtime":1567666227676}],"contextDependencies":[],"result":["'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; /*\n                                                                                                                                                                                                                                                                   * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n                                                                                                                                                                                                                                                                   * or more contributor license agreements. Licensed under the Elastic License;\n                                                                                                                                                                                                                                                                   * you may not use this file except in compliance with the Elastic License.\n                                                                                                                                                                                                                                                                   */\n\n/*\n * Service for the container for the anomaly charts in the\n * Machine Learning Explorer dashboard.\n * The service processes the data required to draw each of the charts\n * and manages the layout of the charts in the containing div.\n */\n\nexports.getDefaultChartsData = getDefaultChartsData;\nexports.explorerChartsContainerServiceFactory = explorerChartsContainerServiceFactory;\n\nvar _lodash = require('lodash');\n\nvar _lodash2 = _interopRequireDefault(_lodash);\n\nvar _explorer_chart_config_builder = require('./explorer_chart_config_builder');\n\nvar _chart_utils = require('../../util/chart_utils');\n\nvar _job_utils = require('../../../common/util/job_utils');\n\nvar _results_service = require('../../services/results_service');\n\nvar _job_service = require('../../services/job_service');\n\nvar _select_severity = require('../../components/controls/select_severity/select_severity');\n\nvar _legacy_utils = require('../legacy_utils');\n\nvar _explorer_constants = require('../explorer_constants');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction getDefaultChartsData() {\n  return {\n    chartsPerRow: 1,\n    seriesToPlot: [],\n    // default values, will update on every re-render\n    tooManyBuckets: false,\n    timeFieldName: 'timestamp'\n  };\n}\n\nfunction explorerChartsContainerServiceFactory(callback) {\n  var FUNCTION_DESCRIPTIONS_TO_PLOT = ['mean', 'min', 'max', 'sum', 'count', 'distinct_count', 'median', 'rare'];\n  var CHART_MAX_POINTS = 500;\n  var ANOMALIES_MAX_RESULTS = 500;\n  var MAX_SCHEDULED_EVENTS = 10; // Max number of scheduled events displayed per bucket.\n  var ML_TIME_FIELD_NAME = 'timestamp';\n  var USE_OVERALL_CHART_LIMITS = false;\n  var MAX_CHARTS_PER_ROW = 4;\n\n  callback(getDefaultChartsData());\n\n  var requestCount = 0;\n  var anomalyDataChange = function anomalyDataChange(anomalyRecords, earliestMs, latestMs) {\n    var newRequestCount = ++requestCount;\n    requestCount = newRequestCount;\n\n    var data = getDefaultChartsData();\n\n    var threshold = _select_severity.mlSelectSeverityService.initalized ? _select_severity.mlSelectSeverityService.state.get('threshold') : _select_severity.SEVERITY_OPTIONS[0];\n\n    var filteredRecords = anomalyRecords.filter(function (record) {\n      return Number(record.record_score) >= threshold.val;\n    });\n    var allSeriesRecords = processRecordsForDisplay(filteredRecords);\n    // Calculate the number of charts per row, depending on the width available, to a max of 4.\n    var chartsContainerWidth = (0, _legacy_utils.getChartContainerWidth)();\n    var chartsPerRow = Math.min(Math.max(Math.floor(chartsContainerWidth / 550), 1), MAX_CHARTS_PER_ROW);\n    if (allSeriesRecords.length === 1) {\n      chartsPerRow = 1;\n    }\n\n    data.chartsPerRow = chartsPerRow;\n\n    // Build the data configs of the anomalies to be displayed.\n    // TODO - implement paging?\n    // For now just take first 6 (or 8 if 4 charts per row).\n    var maxSeriesToPlot = Math.max(chartsPerRow * 2, 6);\n    var recordsToPlot = allSeriesRecords.slice(0, maxSeriesToPlot);\n    var seriesConfigs = recordsToPlot.map(_explorer_chart_config_builder.buildConfig);\n\n    // Calculate the time range of the charts, which is a function of the chart width and max job bucket span.\n    data.tooManyBuckets = false;\n    var chartWidth = Math.floor(chartsContainerWidth / chartsPerRow);\n\n    var _calculateChartRange = calculateChartRange(seriesConfigs, earliestMs, latestMs, chartWidth, recordsToPlot, data.timeFieldName),\n        chartRange = _calculateChartRange.chartRange,\n        tooManyBuckets = _calculateChartRange.tooManyBuckets;\n\n    data.tooManyBuckets = tooManyBuckets;\n\n    // initialize the charts with loading indicators\n    data.seriesToPlot = seriesConfigs.map(function (config) {\n      return _extends({}, config, {\n        loading: true,\n        chartData: null\n      });\n    });\n\n    callback(data);\n\n    // Query 1 - load the raw metric data.\n    function getMetricData(config, range) {\n      var datafeedQuery = _lodash2.default.get(config, 'datafeedConfig.query', null);\n      return _results_service.mlResultsService.getMetricData(config.datafeedConfig.indices, config.datafeedConfig.types, config.entityFields, datafeedQuery, config.metricFunction, config.metricFieldName, config.timeField, range.min, range.max, config.interval);\n    }\n\n    // Query 2 - load the anomalies.\n    // Criteria to return the records for this series are the detector_index plus\n    // the specific combination of 'entity' fields i.e. the partition / by / over fields.\n    function getRecordsForCriteria(config, range) {\n      var criteria = [];\n      criteria.push({ fieldName: 'detector_index', fieldValue: config.detectorIndex });\n      criteria = criteria.concat(config.entityFields);\n      return _results_service.mlResultsService.getRecordsForCriteria([config.jobId], criteria, 0, range.min, range.max, ANOMALIES_MAX_RESULTS);\n    }\n\n    // Query 3 - load any scheduled events for the job.\n    function getScheduledEvents(config, range) {\n      return _results_service.mlResultsService.getScheduledEventsByBucket([config.jobId], range.min, range.max, config.interval, 1, MAX_SCHEDULED_EVENTS);\n    }\n\n    // Query 4 - load context data distribution\n    function getEventDistribution(config, range) {\n      var chartType = (0, _chart_utils.getChartType)(config);\n\n      var splitField = void 0;\n      var filterField = null;\n\n      // Define splitField and filterField based on chartType\n      if (chartType === _explorer_constants.CHART_TYPE.EVENT_DISTRIBUTION) {\n        splitField = config.entityFields.find(function (f) {\n          return f.fieldType === 'by';\n        });\n        filterField = config.entityFields.find(function (f) {\n          return f.fieldType === 'partition';\n        });\n      } else if (chartType === _explorer_constants.CHART_TYPE.POPULATION_DISTRIBUTION) {\n        splitField = config.entityFields.find(function (f) {\n          return f.fieldType === 'over';\n        });\n        filterField = config.entityFields.find(function (f) {\n          return f.fieldType === 'partition';\n        });\n      }\n\n      var datafeedQuery = _lodash2.default.get(config, 'datafeedConfig.query', null);\n      return _results_service.mlResultsService.getEventDistributionData(config.datafeedConfig.indices, config.datafeedConfig.types, splitField, filterField, datafeedQuery, config.metricFunction, config.metricFieldName, config.timeField, range.min, range.max, config.interval);\n    }\n\n    // first load and wait for required data,\n    // only after that trigger data processing and page render.\n    // TODO - if query returns no results e.g. source data has been deleted,\n    // display a message saying 'No data between earliest/latest'.\n    var seriesPromises = seriesConfigs.map(function (seriesConfig) {\n      return Promise.all([getMetricData(seriesConfig, chartRange), getRecordsForCriteria(seriesConfig, chartRange), getScheduledEvents(seriesConfig, chartRange), getEventDistribution(seriesConfig, chartRange)]);\n    });\n\n    function processChartData(response, seriesIndex) {\n      var metricData = response[0].results;\n      var records = response[1].records;\n      var jobId = seriesConfigs[seriesIndex].jobId;\n      var scheduledEvents = response[2].events[jobId];\n      var eventDistribution = response[3];\n      var chartType = (0, _chart_utils.getChartType)(seriesConfigs[seriesIndex]);\n\n      // Return dataset in format used by the chart.\n      // i.e. array of Objects with keys date (timestamp), value,\n      //    plus anomalyScore for points with anomaly markers.\n      if (metricData === undefined || _lodash2.default.keys(metricData).length === 0) {\n        return [];\n      }\n\n      var chartData = void 0;\n      if (eventDistribution.length > 0 && records.length > 0) {\n        var filterField = records[0].by_field_value || records[0].over_field_value;\n        chartData = eventDistribution.filter(function (d) {\n          return d.entity !== filterField;\n        });\n        _lodash2.default.map(metricData, function (value, time) {\n          // The filtering for rare/event_distribution charts needs to be handled\n          // differently because of how the source data is structured.\n          // For rare chart values we are only interested wether a value is either `0` or not,\n          // `0` acts like a flag in the chart whether to display the dot/marker.\n          // All other charts (single metric, population) are metric based and with\n          // those a value of `null` acts as the flag to hide a datapoint.\n          if (chartType === _explorer_constants.CHART_TYPE.EVENT_DISTRIBUTION && value > 0 || chartType !== _explorer_constants.CHART_TYPE.EVENT_DISTRIBUTION && value !== null) {\n            chartData.push({\n              date: +time,\n              value: value,\n              entity: filterField\n            });\n          }\n        });\n      } else {\n        chartData = _lodash2.default.map(metricData, function (value, time) {\n          return {\n            date: +time,\n            value: value\n          };\n        });\n      }\n\n      // Iterate through the anomaly records, adding anomalyScore properties\n      // to the chartData entries for anomalous buckets.\n      var chartDataForPointSearch = getChartDataForPointSearch(chartData, records[0], chartType);\n      _lodash2.default.each(records, function (record) {\n        // Look for a chart point with the same time as the record.\n        // If none found, find closest time in chartData set.\n        var recordTime = record[ML_TIME_FIELD_NAME];\n        var chartPoint = findNearestChartPointToTime(chartDataForPointSearch, recordTime);\n\n        if (chartPoint === undefined) {\n          // In case there is a record with a time after that of the last chart point, set the score\n          // for the last chart point to that of the last record, if that record has a higher score.\n          var lastChartPoint = chartData[chartData.length - 1];\n          var lastChartPointScore = lastChartPoint.anomalyScore || 0;\n          if (record.record_score > lastChartPointScore) {\n            chartPoint = lastChartPoint;\n          }\n        }\n\n        if (chartPoint !== undefined) {\n          chartPoint.anomalyScore = record.record_score;\n\n          if (record.actual !== undefined) {\n            chartPoint.actual = record.actual;\n            chartPoint.typical = record.typical;\n          } else {\n            var causes = _lodash2.default.get(record, 'causes', []);\n            if (causes.length > 0) {\n              chartPoint.byFieldName = record.by_field_name;\n              chartPoint.numberOfCauses = causes.length;\n              if (causes.length === 1) {\n                // If only a single cause, copy actual and typical values to the top level.\n                var cause = _lodash2.default.first(record.causes);\n                chartPoint.actual = cause.actual;\n                chartPoint.typical = cause.typical;\n              }\n            }\n          }\n\n          if (record.multi_bucket_impact !== undefined) {\n            chartPoint.multiBucketImpact = record.multi_bucket_impact;\n          }\n        }\n      });\n\n      // Add a scheduledEvents property to any points in the chart data set\n      // which correspond to times of scheduled events for the job.\n      if (scheduledEvents !== undefined) {\n        _lodash2.default.each(scheduledEvents, function (events, time) {\n          var chartPoint = findNearestChartPointToTime(chartDataForPointSearch, Number(time));\n          if (chartPoint !== undefined) {\n            // Note if the scheduled event coincides with an absence of the underlying metric data,\n            // we don't worry about plotting the event.\n            chartPoint.scheduledEvents = events;\n          }\n        });\n      }\n\n      return chartData;\n    }\n\n    function getChartDataForPointSearch(chartData, record, chartType) {\n      if (chartType === _explorer_constants.CHART_TYPE.EVENT_DISTRIBUTION || chartType === _explorer_constants.CHART_TYPE.POPULATION_DISTRIBUTION) {\n        return chartData.filter(function (d) {\n          return d.entity === (record && (record.by_field_value || record.over_field_value));\n        });\n      }\n\n      return chartData;\n    }\n\n    function findNearestChartPointToTime(chartData, time) {\n      var chartPoint = void 0;\n      for (var i = 0; i < chartData.length; i++) {\n        if (chartData[i].date === time) {\n          chartPoint = chartData[i];\n          break;\n        }\n      }\n\n      if (chartPoint === undefined) {\n        // Find nearest point in time.\n        // loop through line items until the date is greater than bucketTime\n        // grab the current and previous items in the and compare the time differences\n        var foundItem = void 0;\n        for (var _i = 0; _i < chartData.length; _i++) {\n          var itemTime = chartData[_i].date;\n          if (itemTime > time && _i > 0) {\n            var item = chartData[_i];\n            var previousItem = _i > 0 ? chartData[_i - 1] : null;\n\n            var diff1 = Math.abs(time - previousItem.date);\n            var diff2 = Math.abs(time - itemTime);\n\n            // foundItem should be the item with a date closest to bucketTime\n            if (previousItem === null || diff1 > diff2) {\n              foundItem = item;\n            } else {\n              foundItem = previousItem;\n            }\n            break;\n          }\n        }\n\n        chartPoint = foundItem;\n      }\n\n      return chartPoint;\n    }\n\n    Promise.all(seriesPromises).then(function (response) {\n      // TODO: Add test to prevent this regression.\n      // Ignore this response if it's returned by an out of date promise\n      if (newRequestCount < requestCount) {\n        return;\n      }\n      // calculate an overall min/max for all series\n      var processedData = response.map(processChartData);\n      var allDataPoints = _lodash2.default.reduce(processedData, function (datapoints, series) {\n        _lodash2.default.each(series, function (d) {\n          return datapoints.push(d);\n        });\n        return datapoints;\n      }, []);\n      var overallChartLimits = (0, _chart_utils.chartLimits)(allDataPoints);\n\n      data.seriesToPlot = response.map(function (d, i) {\n        return _extends({}, seriesConfigs[i], {\n          loading: false,\n          chartData: processedData[i],\n          plotEarliest: chartRange.min,\n          plotLatest: chartRange.max,\n          selectedEarliest: earliestMs,\n          selectedLatest: latestMs,\n          chartLimits: USE_OVERALL_CHART_LIMITS ? overallChartLimits : (0, _chart_utils.chartLimits)(processedData[i])\n        });\n      });\n      callback(data);\n    }).catch(function (error) {\n      console.error(error);\n    });\n  };\n\n  function processRecordsForDisplay(anomalyRecords) {\n    // Aggregate the anomaly data by detector, and entity (by/over/partition).\n    if (anomalyRecords.length === 0) {\n      return [];\n    }\n\n    // Aggregate by job, detector, and analysis fields (partition, by, over).\n    var aggregatedData = {};\n    _lodash2.default.each(anomalyRecords, function (record) {\n      // Only plot charts for metric functions, and for detectors which don't use categorization\n      // or scripted fields which can be very difficult or impossible to invert to a reverse search.\n      var job = _job_service.mlJobService.getJob(record.job_id);\n      if ((0, _job_utils.isTimeSeriesViewDetector)(job, record.detector_index) === false || FUNCTION_DESCRIPTIONS_TO_PLOT.includes(record.function_description) === false) {\n        return;\n      }\n      var jobId = record.job_id;\n      if (aggregatedData[jobId] === undefined) {\n        aggregatedData[jobId] = {};\n      }\n      var detectorsForJob = aggregatedData[jobId];\n\n      var detectorIndex = record.detector_index;\n      if (detectorsForJob[detectorIndex] === undefined) {\n        detectorsForJob[detectorIndex] = {};\n      }\n\n      // TODO - work out how best to display results from detectors with just an over field.\n      var firstFieldName = record.partition_field_name || record.by_field_name || record.over_field_name;\n      var firstFieldValue = record.partition_field_value || record.by_field_value || record.over_field_value;\n      if (firstFieldName !== undefined) {\n        var groupsForDetector = detectorsForJob[detectorIndex];\n\n        if (groupsForDetector[firstFieldName] === undefined) {\n          groupsForDetector[firstFieldName] = {};\n        }\n        var valuesForGroup = groupsForDetector[firstFieldName];\n        if (valuesForGroup[firstFieldValue] === undefined) {\n          valuesForGroup[firstFieldValue] = {};\n        }\n\n        var dataForGroupValue = valuesForGroup[firstFieldValue];\n\n        var isSecondSplit = false;\n        if (record.partition_field_name !== undefined) {\n          var splitFieldName = record.over_field_name || record.by_field_name;\n          if (splitFieldName !== undefined) {\n            isSecondSplit = true;\n          }\n        }\n\n        if (isSecondSplit === false) {\n          if (dataForGroupValue.maxScoreRecord === undefined) {\n            dataForGroupValue.maxScore = record.record_score;\n            dataForGroupValue.maxScoreRecord = record;\n          } else {\n            if (record.record_score > dataForGroupValue.maxScore) {\n              dataForGroupValue.maxScore = record.record_score;\n              dataForGroupValue.maxScoreRecord = record;\n            }\n          }\n        } else {\n          // Aggregate another level for the over or by field.\n          var secondFieldName = record.over_field_name || record.by_field_name;\n          var secondFieldValue = record.over_field_value || record.by_field_value;\n\n          if (dataForGroupValue[secondFieldName] === undefined) {\n            dataForGroupValue[secondFieldName] = {};\n          }\n\n          var splitsForGroup = dataForGroupValue[secondFieldName];\n          if (splitsForGroup[secondFieldValue] === undefined) {\n            splitsForGroup[secondFieldValue] = {};\n          }\n\n          var dataForSplitValue = splitsForGroup[secondFieldValue];\n          if (dataForSplitValue.maxScoreRecord === undefined) {\n            dataForSplitValue.maxScore = record.record_score;\n            dataForSplitValue.maxScoreRecord = record;\n          } else {\n            if (record.record_score > dataForSplitValue.maxScore) {\n              dataForSplitValue.maxScore = record.record_score;\n              dataForSplitValue.maxScoreRecord = record;\n            }\n          }\n        }\n      } else {\n        // Detector with no partition or by field.\n        var dataForDetector = detectorsForJob[detectorIndex];\n        if (dataForDetector.maxScoreRecord === undefined) {\n          dataForDetector.maxScore = record.record_score;\n          dataForDetector.maxScoreRecord = record;\n        } else {\n          if (record.record_score > dataForDetector.maxScore) {\n            dataForDetector.maxScore = record.record_score;\n            dataForDetector.maxScoreRecord = record;\n          }\n        }\n      }\n    });\n\n    console.log('explorer charts aggregatedData is:', aggregatedData);\n    var recordsForSeries = [];\n    // Convert to an array of the records with the highest record_score per unique series.\n    _lodash2.default.each(aggregatedData, function (detectorsForJob) {\n      _lodash2.default.each(detectorsForJob, function (groupsForDetector) {\n        if (groupsForDetector.maxScoreRecord !== undefined) {\n          // Detector with no partition / by field.\n          recordsForSeries.push(groupsForDetector.maxScoreRecord);\n        } else {\n          _lodash2.default.each(groupsForDetector, function (valuesForGroup) {\n            _lodash2.default.each(valuesForGroup, function (dataForGroupValue) {\n              if (dataForGroupValue.maxScoreRecord !== undefined) {\n                recordsForSeries.push(dataForGroupValue.maxScoreRecord);\n              } else {\n                // Second level of aggregation for partition and by/over.\n                _lodash2.default.each(dataForGroupValue, function (splitsForGroup) {\n                  _lodash2.default.each(splitsForGroup, function (dataForSplitValue) {\n                    recordsForSeries.push(dataForSplitValue.maxScoreRecord);\n                  });\n                });\n              }\n            });\n          });\n        }\n      });\n    });\n    recordsForSeries = _lodash2.default.sortBy(recordsForSeries, 'record_score').reverse();\n\n    return recordsForSeries;\n  }\n\n  function calculateChartRange(seriesConfigs, earliestMs, latestMs, chartWidth, recordsToPlot, timeFieldName) {\n    var tooManyBuckets = false;\n    // Calculate the time range for the charts.\n    // Fit in as many points in the available container width plotted at the job bucket span.\n    var midpointMs = Math.ceil((earliestMs + latestMs) / 2);\n    var maxBucketSpanMs = Math.max.apply(null, _lodash2.default.pluck(seriesConfigs, 'bucketSpanSeconds')) * 1000;\n\n    var pointsToPlotFullSelection = Math.ceil((latestMs - earliestMs) / maxBucketSpanMs);\n\n    // Optimally space points 5px apart.\n    var optimumPointSpacing = 5;\n    var optimumNumPoints = chartWidth / optimumPointSpacing;\n\n    // Increase actual number of points if we can't plot the selected range\n    // at optimal point spacing.\n    var plotPoints = Math.max(optimumNumPoints, pointsToPlotFullSelection);\n    var halfPoints = Math.ceil(plotPoints / 2);\n    var chartRange = {\n      min: midpointMs - halfPoints * maxBucketSpanMs,\n      max: midpointMs + halfPoints * maxBucketSpanMs\n    };\n\n    if (plotPoints > CHART_MAX_POINTS) {\n      tooManyBuckets = true;\n      // For each series being plotted, display the record with the highest score if possible.\n      var maxTimeSpan = maxBucketSpanMs * CHART_MAX_POINTS;\n      var minMs = recordsToPlot[0][timeFieldName];\n      var maxMs = recordsToPlot[0][timeFieldName];\n\n      _lodash2.default.each(recordsToPlot, function (record) {\n        var diffMs = maxMs - minMs;\n        if (diffMs < maxTimeSpan) {\n          var recordTime = record[timeFieldName];\n          if (recordTime < minMs) {\n            if (maxMs - recordTime <= maxTimeSpan) {\n              minMs = recordTime;\n            }\n          }\n\n          if (recordTime > maxMs) {\n            if (recordTime - minMs <= maxTimeSpan) {\n              maxMs = recordTime;\n            }\n          }\n        }\n      });\n\n      if (maxMs - minMs < maxTimeSpan) {\n        // Expand out to cover as much as the requested time span as possible.\n        minMs = Math.max(earliestMs, minMs - maxTimeSpan);\n        maxMs = Math.min(latestMs, maxMs + maxTimeSpan);\n      }\n\n      chartRange = { min: minMs, max: maxMs };\n    }\n\n    return {\n      chartRange: chartRange,\n      tooManyBuckets: tooManyBuckets\n    };\n  }\n\n  return anomalyDataChange;\n}",null]}