{"remainingRequest":"/home/anthony/git_workspaces/kibana/node_modules/thread-loader/dist/cjs.js??ref--9-1!/home/anthony/git_workspaces/kibana/node_modules/babel-loader/lib/index.js??ref--9-2!/home/anthony/git_workspaces/kibana/x-pack/plugins/ml/public/file_datavisualizer/components/import_view/importer/importer.js","dependencies":[{"path":"/home/anthony/git_workspaces/kibana/x-pack/plugins/ml/public/file_datavisualizer/components/import_view/importer/importer.js","mtime":1567631712045},{"path":"/home/anthony/git_workspaces/kibana/node_modules/cache-loader/dist/cjs.js","mtime":1567666236302},{"path":"/home/anthony/git_workspaces/kibana/node_modules/thread-loader/dist/cjs.js","mtime":1567666239443},{"path":"/home/anthony/git_workspaces/kibana/node_modules/babel-loader/lib/index.js","mtime":1567666227676}],"contextDependencies":[],"result":["'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Importer = undefined;\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }(); /*\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      * or more contributor license agreements. Licensed under the Elastic License;\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      * you may not use this file except in compliance with the Elastic License.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      */\n\nvar _ml_api_service = require('../../../../services/ml_api_service');\n\nvar _lodash = require('lodash');\n\nvar _moment = require('moment');\n\nvar _moment2 = _interopRequireDefault(_moment);\n\nvar _i18n = require('@kbn/i18n');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\nfunction _asyncToGenerator(fn) { return function () { var gen = fn.apply(this, arguments); return new Promise(function (resolve, reject) { function step(key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { return Promise.resolve(value).then(function (value) { step(\"next\", value); }, function (err) { step(\"throw\", err); }); } } return step(\"next\"); }); }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar CHUNK_SIZE = 10000;\nvar IMPORT_RETRIES = 5;\n\nvar Importer = exports.Importer = function () {\n  function Importer(_ref) {\n    var settings = _ref.settings,\n        mappings = _ref.mappings,\n        pipeline = _ref.pipeline;\n\n    _classCallCheck(this, Importer);\n\n    this.settings = settings;\n    this.mappings = mappings;\n    this.pipeline = pipeline;\n\n    this.data = [];\n    this.docArray = [];\n  }\n\n  _createClass(Importer, [{\n    key: 'initializeImport',\n    value: function () {\n      var _ref2 = _asyncToGenerator( /*#__PURE__*/regeneratorRuntime.mark(function _callee(index) {\n        var settings, mappings, pipeline, ingestPipeline, createIndexResp;\n        return regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                settings = this.settings;\n                mappings = this.mappings;\n                pipeline = this.pipeline;\n\n                updatePipelineTimezone(pipeline);\n\n                // if no pipeline has been supplied,\n                // send an empty object\n                ingestPipeline = pipeline !== undefined ? {\n                  id: index + '-pipeline',\n                  pipeline: pipeline\n                } : {};\n                _context.next = 7;\n                return _ml_api_service.ml.fileDatavisualizer.import({\n                  id: undefined,\n                  index: index,\n                  data: [],\n                  settings: settings,\n                  mappings: mappings,\n                  ingestPipeline: ingestPipeline\n                });\n\n              case 7:\n                createIndexResp = _context.sent;\n                return _context.abrupt('return', createIndexResp);\n\n              case 9:\n              case 'end':\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function initializeImport(_x) {\n        return _ref2.apply(this, arguments);\n      }\n\n      return initializeImport;\n    }()\n  }, {\n    key: 'import',\n    value: function () {\n      var _ref3 = _asyncToGenerator( /*#__PURE__*/regeneratorRuntime.mark(function _callee2(id, index, pipelineId, setImportProgress) {\n        var chunks, ingestPipeline, success, failures, error, i, aggs, retries, resp, result;\n        return regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                if (!(!id || !index)) {\n                  _context2.next = 2;\n                  break;\n                }\n\n                return _context2.abrupt('return', {\n                  success: false,\n                  error: _i18n.i18n.translate('xpack.ml.fileDatavisualizer.importView.noIdOrIndexSuppliedErrorMessage', {\n                    defaultMessage: 'no ID or index supplied'\n                  })\n                });\n\n              case 2:\n                chunks = (0, _lodash.chunk)(this.docArray, CHUNK_SIZE);\n                ingestPipeline = {\n                  id: pipelineId\n                };\n                success = true;\n                failures = [];\n                error = void 0;\n                i = 0;\n\n              case 8:\n                if (!(i < chunks.length)) {\n                  _context2.next = 33;\n                  break;\n                }\n\n                aggs = {\n                  id: id,\n                  index: index,\n                  data: chunks[i],\n                  settings: {},\n                  mappings: {},\n                  ingestPipeline: ingestPipeline\n                };\n                retries = IMPORT_RETRIES;\n                resp = {\n                  success: false,\n                  failures: [],\n                  docCount: 0\n                };\n\n              case 12:\n                if (!(resp.success === false && retries > 0)) {\n                  _context2.next = 20;\n                  break;\n                }\n\n                _context2.next = 15;\n                return _ml_api_service.ml.fileDatavisualizer.import(aggs);\n\n              case 15:\n                resp = _context2.sent;\n\n\n                if (retries < IMPORT_RETRIES) {\n                  console.log('Retrying import ' + (IMPORT_RETRIES - retries));\n                }\n\n                retries--;\n                _context2.next = 12;\n                break;\n\n              case 20:\n                if (!resp.success) {\n                  _context2.next = 24;\n                  break;\n                }\n\n                setImportProgress((i + 1) / chunks.length * 100);\n                _context2.next = 29;\n                break;\n\n              case 24:\n                console.error(resp);\n                success = false;\n                error = resp.error;\n                populateFailures(resp, failures, i);\n                return _context2.abrupt('break', 33);\n\n              case 29:\n\n                populateFailures(resp, failures, i);\n\n              case 30:\n                i++;\n                _context2.next = 8;\n                break;\n\n              case 33:\n                result = {\n                  success: success,\n                  failures: failures,\n                  docCount: this.docArray.length\n                };\n\n\n                if (success) {\n                  setImportProgress(100);\n                } else {\n                  result.error = error;\n                }\n\n                return _context2.abrupt('return', result);\n\n              case 36:\n              case 'end':\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function _import(_x2, _x3, _x4, _x5) {\n        return _ref3.apply(this, arguments);\n      }\n\n      return _import;\n    }()\n  }]);\n\n  return Importer;\n}();\n\nfunction populateFailures(error, failures, chunkCount) {\n  if (error.failures && error.failures.length) {\n    // update the item value to include the chunk count\n    // e.g. item 3 in chunk 2 is actually item 20003\n    for (var f = 0; f < error.failures.length; f++) {\n      var failure = error.failures[f];\n      failure.item = failure.item + CHUNK_SIZE * chunkCount;\n    }\n    failures.push.apply(failures, _toConsumableArray(error.failures));\n  }\n}\n\n// The file structure endpoint sets the timezone to be {{ beat.timezone }}\n// as that's the variable Filebeat would send the client timezone in.\n// In this data import function the UI is effectively performing the role of Filebeat,\n// i.e. doing basic parsing, processing and conversion to JSON before forwarding to the ingest pipeline.\n// But it's not sending every single field that Filebeat would add, so the ingest pipeline\n// cannot look for a beat.timezone variable in each input record.\n// Therefore we need to replace {{ beat.timezone }} with the actual browser timezone\nfunction updatePipelineTimezone(ingestPipeline) {\n  if (ingestPipeline !== undefined && ingestPipeline.processors && ingestPipeline.processors) {\n    var dateProcessor = ingestPipeline.processors.find(function (p) {\n      return p.date !== undefined && p.date.timezone === '{{ beat.timezone }}';\n    });\n\n    if (dateProcessor) {\n      dateProcessor.date.timezone = _moment2.default.tz.guess();\n    }\n  }\n}",null]}