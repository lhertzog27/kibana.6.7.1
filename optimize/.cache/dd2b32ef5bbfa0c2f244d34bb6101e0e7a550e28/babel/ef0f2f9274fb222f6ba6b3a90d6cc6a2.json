{"remainingRequest":"/home/anthony/git_workspaces/kibana/node_modules/thread-loader/dist/cjs.js??ref--9-1!/home/anthony/git_workspaces/kibana/node_modules/babel-loader/lib/index.js??ref--9-2!/home/anthony/git_workspaces/kibana/x-pack/plugins/ml/common/util/job_utils.js","dependencies":[{"path":"/home/anthony/git_workspaces/kibana/x-pack/plugins/ml/common/util/job_utils.js","mtime":1567631712025},{"path":"/home/anthony/git_workspaces/kibana/node_modules/cache-loader/dist/cjs.js","mtime":1567666236302},{"path":"/home/anthony/git_workspaces/kibana/node_modules/thread-loader/dist/cjs.js","mtime":1567666239443},{"path":"/home/anthony/git_workspaces/kibana/node_modules/babel-loader/lib/index.js","mtime":1567666227676}],"contextDependencies":[],"result":["'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.ML_DATA_PREVIEW_COUNT = exports.ML_MEDIAN_PERCENTS = undefined;\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\nexports.calculateDatafeedFrequencyDefaultSeconds = calculateDatafeedFrequencyDefaultSeconds;\nexports.isTimeSeriesViewJob = isTimeSeriesViewJob;\nexports.isTimeSeriesViewDetector = isTimeSeriesViewDetector;\nexports.isTimeSeriesViewFunction = isTimeSeriesViewFunction;\nexports.getPartitioningFieldNames = getPartitioningFieldNames;\nexports.isModelPlotEnabled = isModelPlotEnabled;\nexports.isJobVersionGte = isJobVersionGte;\nexports.mlFunctionToESAggregation = mlFunctionToESAggregation;\nexports.isJobIdValid = isJobIdValid;\nexports.prefixDatafeedId = prefixDatafeedId;\nexports.getSafeAggregationName = getSafeAggregationName;\nexports.uniqWithIsEqual = uniqWithIsEqual;\nexports.basicJobValidation = basicJobValidation;\nexports.validateModelMemoryLimit = validateModelMemoryLimit;\nexports.validateModelMemoryLimitUnits = validateModelMemoryLimitUnits;\nexports.validateGroupNames = validateGroupNames;\n\nvar _lodash = require('lodash');\n\nvar _lodash2 = _interopRequireDefault(_lodash);\n\nvar _semver = require('semver');\n\nvar _semver2 = _interopRequireDefault(_semver);\n\nvar _numeral = require('@elastic/numeral');\n\nvar _numeral2 = _interopRequireDefault(_numeral);\n\nvar _validation = require('../constants/validation');\n\nvar _parse_interval = require('./parse_interval');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } } /*\n                                                                                                                                                                                                     * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n                                                                                                                                                                                                     * or more contributor license agreements. Licensed under the Elastic License;\n                                                                                                                                                                                                     * you may not use this file except in compliance with the Elastic License.\n                                                                                                                                                                                                     */\n\n// work out the default frequency based on the bucket_span in seconds\nfunction calculateDatafeedFrequencyDefaultSeconds(bucketSpanSeconds) {\n\n  var freq = 3600;\n  if (bucketSpanSeconds <= 120) {\n    freq = 60;\n  } else if (bucketSpanSeconds <= 1200) {\n    freq = Math.floor(bucketSpanSeconds / 2);\n  } else if (bucketSpanSeconds <= 43200) {\n    freq = 600;\n  }\n\n  return freq;\n}\n\n// Returns a flag to indicate whether the job is suitable for viewing\n// in the Time Series dashboard.\nfunction isTimeSeriesViewJob(job) {\n  // TODO - do we need another function which returns whether to enable the\n  // link to the Single Metric dashboard in the Jobs list, only allowing single\n  // metric jobs with only one detector with no by/over/partition fields\n\n  // only allow jobs with at least one detector whose function corresponds to\n  // an ES aggregation which can be viewed in the single metric view and which\n  // doesn't use a scripted field which can be very difficult or impossible to\n  // invert to a reverse search.\n  var isViewable = false;\n  var dtrs = job.analysis_config.detectors;\n\n  for (var i = 0; i < dtrs.length; i++) {\n    isViewable = isTimeSeriesViewDetector(job, i);\n    if (isViewable === true) {\n      break;\n    }\n  }\n\n  return isViewable;\n}\n\n// Returns a flag to indicate whether the detector at the index in the specified job\n// is suitable for viewing in the Time Series dashboard.\nfunction isTimeSeriesViewDetector(job, dtrIndex) {\n  // Check that the detector function is suitable for viewing in the Time Series dashboard,\n  // and that the partition, by and over fields are not using mlcategory or a scripted field which\n  // can be very difficult or impossible to invert to a reverse search of the underlying metric data.\n  var isDetectorViewable = false;\n\n  var dtrs = job.analysis_config.detectors;\n  if (dtrIndex >= 0 && dtrIndex < dtrs.length) {\n    var dtr = dtrs[dtrIndex];\n    isDetectorViewable = isTimeSeriesViewFunction(dtr.function) === true && dtr.by_field_name !== 'mlcategory' && dtr.partition_field_name !== 'mlcategory' && dtr.over_field_name !== 'mlcategory';\n\n    var usesScriptFields = _lodash2.default.has(job, 'datafeed_config.script_fields');\n    if (isDetectorViewable === true && usesScriptFields === true) {\n      // Perform extra check to see if the detector is using a scripted field.\n      var scriptFields = usesScriptFields ? _lodash2.default.keys(job.datafeed_config.script_fields) : [];\n      isDetectorViewable = scriptFields.indexOf(dtr.field_name) === -1 && scriptFields.indexOf(dtr.partition_field_name) === -1 && scriptFields.indexOf(dtr.by_field_name) === -1 && scriptFields.indexOf(dtr.over_field_name) === -1;\n    }\n  }\n\n  return isDetectorViewable;\n}\n\n// Returns a flag to indicate whether a detector with the specified function is\n// suitable for viewing in the Time Series dashboard.\nfunction isTimeSeriesViewFunction(functionName) {\n  return mlFunctionToESAggregation(functionName) !== null;\n}\n\n// Returns the names of the partition, by, and over fields for the detector with the\n// specified index from the supplied ML job configuration.\nfunction getPartitioningFieldNames(job, detectorIndex) {\n  var fieldNames = [];\n  var detector = job.analysis_config.detectors[detectorIndex];\n  if (_lodash2.default.has(detector, 'partition_field_name')) {\n    fieldNames.push(detector.partition_field_name);\n  }\n  if (_lodash2.default.has(detector, 'by_field_name')) {\n    fieldNames.push(detector.by_field_name);\n  }\n  if (_lodash2.default.has(detector, 'over_field_name')) {\n    fieldNames.push(detector.over_field_name);\n  }\n\n  return fieldNames;\n}\n\n// Returns a flag to indicate whether model plot has been enabled for a job.\n// If model plot is enabled for a job with a terms filter (comma separated\n// list of partition or by field names), performs additional checks that\n// the supplied entities contains 'by' and 'partition' fields in the detector,\n// if configured, whose values are in the configured model_plot_config terms,\n// where entityFields is in the format [{fieldName:status, fieldValue:404}].\nfunction isModelPlotEnabled(job, detectorIndex, entityFields) {\n  // Check if model_plot_config is enabled.\n  var isEnabled = _lodash2.default.get(job, ['model_plot_config', 'enabled'], false);\n\n  if (isEnabled === true) {\n    // If terms filter is configured in model_plot_config, check supplied entities.\n    var termsStr = _lodash2.default.get(job, ['model_plot_config', 'terms'], '');\n    if (termsStr !== '') {\n      // NB. Do not currently support empty string values as being valid 'by' or\n      // 'partition' field values even though this is supported on the back-end.\n      // If supplied, check both the by and partition entities are in the terms.\n      var detector = job.analysis_config.detectors[detectorIndex];\n      var detectorHasPartitionField = _lodash2.default.has(detector, 'partition_field_name');\n      var detectorHasByField = _lodash2.default.has(detector, 'by_field_name');\n      var terms = termsStr.split(',');\n\n      if (detectorHasPartitionField === true) {\n        var partitionEntity = _lodash2.default.find(entityFields, { 'fieldName': detector.partition_field_name });\n        isEnabled = partitionEntity !== undefined && terms.indexOf(partitionEntity.fieldValue) !== -1;\n      }\n\n      if (isEnabled === true && detectorHasByField === true) {\n        var byEntity = _lodash2.default.find(entityFields, { 'fieldName': detector.by_field_name });\n        isEnabled = byEntity !== undefined && terms.indexOf(byEntity.fieldValue) !== -1;\n      }\n    }\n  }\n\n  return isEnabled;\n}\n\n// Returns whether the version of the job (the version number of the elastic stack that the job was\n// created with) is greater than or equal to the supplied version (e.g. '6.1.0').\nfunction isJobVersionGte(job, version) {\n  var jobVersion = _lodash2.default.get(job, 'job_version', '0.0.0');\n  return _semver2.default.gte(jobVersion, version);\n}\n\n// Takes an ML detector 'function' and returns the corresponding ES aggregation name\n// for querying metric data. Returns null if there is no suitable ES aggregation.\n// Note that the 'function' field in a record contains what the user entered e.g. 'high_count',\n// whereas the 'function_description' field holds an ML-built display hint for function e.g. 'count'.\nfunction mlFunctionToESAggregation(functionName) {\n  if (functionName === 'mean' || functionName === 'high_mean' || functionName === 'low_mean' || functionName === 'metric') {\n    return 'avg';\n  }\n\n  if (functionName === 'sum' || functionName === 'high_sum' || functionName === 'low_sum' || functionName === 'non_null_sum' || functionName === 'low_non_null_sum' || functionName === 'high_non_null_sum') {\n    return 'sum';\n  }\n\n  if (functionName === 'count' || functionName === 'high_count' || functionName === 'low_count' || functionName === 'non_zero_count' || functionName === 'low_non_zero_count' || functionName === 'high_non_zero_count') {\n    return 'count';\n  }\n\n  if (functionName === 'distinct_count' || functionName === 'low_distinct_count' || functionName === 'high_distinct_count') {\n    return 'cardinality';\n  }\n\n  if (functionName === 'median' || functionName === 'high_median' || functionName === 'low_median') {\n    return 'percentiles';\n  }\n\n  if (functionName === 'min' || functionName === 'max') {\n    return functionName;\n  }\n\n  if (functionName === 'rare') {\n    return 'count';\n  }\n\n  // Return null if ML function does not map to an ES aggregation.\n  // i.e. median, low_median, high_median, freq_rare,\n  // varp, low_varp, high_varp, time_of_day, time_of_week, lat_long,\n  // info_content, low_info_content, high_info_content\n  return null;\n}\n\n// Job name must contain lowercase alphanumeric (a-z and 0-9), hyphens or underscores;\n// it must also start and end with an alphanumeric character'\nfunction isJobIdValid(jobId) {\n  return jobId.match(/^[a-z0-9\\-\\_]{1,64}$/g) && !jobId.match(/^([_-].*)?(.*[_-])?$/g) ? true : false;\n}\n\n// To get median data for jobs and charts we need to use Elasticsearch's\n// percentiles aggregation. This setting is used with the `percents` field\n// of the percentiles aggregation to get the correct data.\nvar ML_MEDIAN_PERCENTS = exports.ML_MEDIAN_PERCENTS = '50.0';\n\n// The number of preview items to show up in\n// the Advanced Job Configuration data/datafeed preview tab\nvar ML_DATA_PREVIEW_COUNT = exports.ML_DATA_PREVIEW_COUNT = 10;\n\n// add a prefix to a datafeed id before the \"datafeed-\" part of the name\nfunction prefixDatafeedId(datafeedId, prefix) {\n  return datafeedId.match(/^datafeed-/) ? datafeedId.replace(/^datafeed-/, 'datafeed-' + prefix) : '' + prefix + datafeedId;\n}\n\n// Returns a name which is safe to use in elasticsearch aggregations for the supplied\n// field name. Aggregation names must be alpha-numeric and can only contain '_' and '-' characters,\n// so if the supplied field names contains disallowed characters, the provided index\n// identifier is used to return a safe 'dummy' name in the format 'field_index' e.g. field_0, field_1\nfunction getSafeAggregationName(fieldName, index) {\n  return fieldName.match(/^[a-zA-Z0-9-_.]+$/) ? fieldName : 'field_' + index;\n}\n\nfunction uniqWithIsEqual(arr) {\n  return arr.reduce(function (dedupedArray, value) {\n    if (dedupedArray.filter(function (compareValue) {\n      return _lodash2.default.isEqual(compareValue, value);\n    }).length === 0) {\n      dedupedArray.push(value);\n    }\n    return dedupedArray;\n  }, []);\n}\n\n// check job without manipulating UI and return a list of messages\n// job and fields get passed as arguments and are not accessed as $scope.* via the outer scope\n// because the plan is to move this function to the common code area so that it can be used on the server side too.\nfunction basicJobValidation(job, fields, limits) {\n  var skipMmlChecks = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n\n  var messages = [];\n  var valid = true;\n\n  if (job) {\n    // Job details\n    if (_lodash2.default.isEmpty(job.job_id)) {\n      messages.push({ id: 'job_id_empty' });\n      valid = false;\n    } else if (isJobIdValid(job.job_id) === false) {\n      messages.push({ id: 'job_id_invalid' });\n      valid = false;\n    } else {\n      messages.push({ id: 'job_id_valid' });\n    }\n\n    // group names\n\n    var _validateGroupNames = validateGroupNames(job),\n        groupsMessages = _validateGroupNames.messages,\n        groupsValid = _validateGroupNames.valid;\n\n    messages.push.apply(messages, _toConsumableArray(groupsMessages));\n    valid = valid && groupsValid;\n\n    // Analysis Configuration\n    if (job.analysis_config.categorization_filters) {\n      var v = true;\n      _lodash2.default.each(job.analysis_config.categorization_filters, function (d) {\n        try {\n          new RegExp(d);\n        } catch (e) {\n          v = false;\n        }\n\n        if (job.analysis_config.categorization_field_name === undefined || job.analysis_config.categorization_field_name === '') {\n          v = false;\n        }\n\n        if (d === '') {\n          v = false;\n        }\n      });\n\n      if (v) {\n        messages.push({ id: 'categorization_filters_valid' });\n      } else {\n        messages.push({ id: 'categorization_filters_invalid' });\n        valid = false;\n      }\n    }\n\n    if (job.analysis_config.detectors.length === 0) {\n      messages.push({ id: 'detectors_empty' });\n      valid = false;\n    } else {\n      var _v = true;\n      _lodash2.default.each(job.analysis_config.detectors, function (d) {\n        if (_lodash2.default.isEmpty(d.function)) {\n          _v = false;\n        }\n      });\n      if (_v) {\n        messages.push({ id: 'detectors_function_not_empty' });\n      } else {\n        messages.push({ id: 'detectors_function_empty' });\n        valid = false;\n      }\n    }\n\n    // check for duplicate detectors\n    if (job.analysis_config.detectors.length >= 2) {\n      // create an array of objects with a subset of the attributes\n      // where we want to make sure they are not be the same across detectors\n      var compareSubSet = job.analysis_config.detectors.map(function (d) {\n        return _lodash2.default.pick(d, ['function', 'field_name', 'by_field_name', 'over_field_name', 'partition_field_name']);\n      });\n\n      var dedupedSubSet = uniqWithIsEqual(compareSubSet);\n\n      if (compareSubSet.length !== dedupedSubSet.length) {\n        messages.push({ id: 'detectors_duplicates' });\n        valid = false;\n      }\n    }\n\n    // we skip this influencer test because the client side form check is ignoring it\n    // and the server side tests have their own influencer test\n    // TODO: clarify if this is still needed or can be deleted\n    /*\n    if (job.analysis_config.influencers &&\n      job.analysis_config.influencers.length === 0) {\n      messages.push({ id: 'influencers_low' });\n      valid = false;\n    } else {\n      messages.push({ id: 'success_influencers' });\n    }\n    */\n\n    if (job.analysis_config.bucket_span === '' || job.analysis_config.bucket_span === undefined) {\n      messages.push({ id: 'bucket_span_empty' });\n      valid = false;\n    } else {\n      var bucketSpan = (0, _parse_interval.parseInterval)(job.analysis_config.bucket_span, false);\n      if (bucketSpan === null || bucketSpan.asMilliseconds() === 0) {\n        messages.push({ id: 'bucket_span_invalid' });\n        valid = false;\n      } else {\n        messages.push({\n          id: 'bucket_span_valid',\n          bucketSpan: job.analysis_config.bucket_span\n        });\n      }\n    }\n\n    // Datafeed\n    if (typeof fields !== 'undefined') {\n      var loadedFields = Object.keys(fields);\n      if (loadedFields.length === 0) {\n        messages.push({ id: 'index_fields_invalid' });\n        valid = false;\n      } else {\n        messages.push({ id: 'index_fields_valid' });\n      }\n    }\n\n    if (skipMmlChecks === false) {\n      // model memory limit\n      var _validateModelMemoryL = validateModelMemoryLimitUnits(job),\n          mmlUnitMessages = _validateModelMemoryL.messages,\n          mmlUnitValid = _validateModelMemoryL.valid;\n\n      messages.push.apply(messages, _toConsumableArray(mmlUnitMessages));\n      valid = valid && mmlUnitValid;\n\n      if (mmlUnitValid) {\n        // if mml is a valid format,\n        // run the validation against max mml\n        var _validateModelMemoryL2 = validateModelMemoryLimit(job, limits),\n            mmlMessages = _validateModelMemoryL2.messages,\n            mmlValid = _validateModelMemoryL2.valid;\n\n        messages.push.apply(messages, _toConsumableArray(mmlMessages));\n        valid = valid && mmlValid;\n      }\n    }\n  } else {\n    valid = false;\n  }\n\n  return {\n    messages: messages,\n    valid: valid,\n    contains: function contains(id) {\n      return messages.some(function (m) {\n        return id === m.id;\n      });\n    },\n    find: function find(id) {\n      return messages.find(function (m) {\n        return id === m.id;\n      });\n    }\n  };\n}\n\nfunction validateModelMemoryLimit(job, limits) {\n  var messages = [];\n  var valid = true;\n  // model memory limit\n  if (typeof job.analysis_limits !== 'undefined' && typeof job.analysis_limits.model_memory_limit !== 'undefined') {\n    if ((typeof limits === 'undefined' ? 'undefined' : _typeof(limits)) === 'object' && typeof limits.max_model_memory_limit !== 'undefined') {\n      var max = limits.max_model_memory_limit.toUpperCase();\n      var mml = job.analysis_limits.model_memory_limit.toUpperCase();\n\n      var mmlBytes = (0, _numeral2.default)(mml).value();\n      var maxBytes = (0, _numeral2.default)(max).value();\n\n      if (mmlBytes > maxBytes) {\n        messages.push({ id: 'model_memory_limit_invalid' });\n        valid = false;\n      } else {\n        messages.push({ id: 'model_memory_limit_valid' });\n      }\n    }\n  }\n  return {\n    valid: valid,\n    messages: messages,\n    contains: function contains(id) {\n      return messages.some(function (m) {\n        return id === m.id;\n      });\n    },\n    find: function find(id) {\n      return messages.find(function (m) {\n        return id === m.id;\n      });\n    }\n  };\n}\n\nfunction validateModelMemoryLimitUnits(job) {\n  var messages = [];\n  var valid = true;\n\n  if (typeof job.analysis_limits !== 'undefined' && typeof job.analysis_limits.model_memory_limit !== 'undefined') {\n    var mml = job.analysis_limits.model_memory_limit.toUpperCase();\n    var mmlSplit = mml.match(/\\d+(\\w+)/);\n    var unit = mmlSplit && mmlSplit.length === 2 ? mmlSplit[1] : null;\n\n    if (_validation.ALLOWED_DATA_UNITS.indexOf(unit) === -1) {\n      messages.push({ id: 'model_memory_limit_units_invalid' });\n      valid = false;\n    } else {\n      messages.push({ id: 'model_memory_limit_units_valid' });\n    }\n  }\n  return {\n    valid: valid,\n    messages: messages,\n    contains: function contains(id) {\n      return messages.some(function (m) {\n        return id === m.id;\n      });\n    },\n    find: function find(id) {\n      return messages.find(function (m) {\n        return id === m.id;\n      });\n    }\n  };\n}\n\nfunction validateGroupNames(job) {\n  var messages = [];\n  var valid = true;\n  if (job.groups !== undefined) {\n    var groupIdValid = true;\n    job.groups.forEach(function (group) {\n      if (isJobIdValid(group) === false) {\n        groupIdValid = false;\n        valid = false;\n      }\n    });\n    if (job.groups.length > 0 && groupIdValid) {\n      messages.push({ id: 'job_group_id_valid' });\n    } else if (job.groups.length > 0 && !groupIdValid) {\n      messages.push({ id: 'job_group_id_invalid' });\n    }\n  }\n  return {\n    valid: valid,\n    messages: messages,\n    contains: function contains(id) {\n      return messages.some(function (m) {\n        return id === m.id;\n      });\n    },\n    find: function find(id) {\n      return messages.find(function (m) {\n        return id === m.id;\n      });\n    }\n  };\n}",null]}